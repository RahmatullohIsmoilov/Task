def answer_question(query):
    """
    Example: integrate with OpenAI embeddings + vector DB for retrieval
    Return None if unable to answer
    """
    # Pseudocode:
    # context = vector_db.retrieve(query)
    # if context:
    #     return llm.generate_answer(query, context)
    # return None
    return "This is a placeholder answer from RAG."
